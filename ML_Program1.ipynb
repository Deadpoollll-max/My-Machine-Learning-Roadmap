{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e98066a5-d66c-4745-8e45-d65a6ba02d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.utils._bunch.Bunch'>\n",
      "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])\n",
      "[[1.799e+01 1.038e+01 1.228e+02 ... 2.654e-01 4.601e-01 1.189e-01]\n",
      " [2.057e+01 1.777e+01 1.329e+02 ... 1.860e-01 2.750e-01 8.902e-02]\n",
      " [1.969e+01 2.125e+01 1.300e+02 ... 2.430e-01 3.613e-01 8.758e-02]\n",
      " ...\n",
      " [1.660e+01 2.808e+01 1.083e+02 ... 1.418e-01 2.218e-01 7.820e-02]\n",
      " [2.060e+01 2.933e+01 1.401e+02 ... 2.650e-01 4.087e-01 1.240e-01]\n",
      " [7.760e+00 2.454e+01 4.792e+01 ... 0.000e+00 2.871e-01 7.039e-02]]\n",
      "(569, 30)\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 1 0 1 1 1 1 1 0 0 1 0 0 1 1 1 1 0 1 0 0 1 1 1 1 0 1 0 0\n",
      " 1 0 1 0 0 1 1 1 0 0 1 0 0 0 1 1 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1\n",
      " 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 0 0 1 0 1 0 0 1 0 0 1 1 0 1 1 0 1 1 1 1 0 1\n",
      " 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 0 1 1 0 0 1 1 0 0 1 1 1 1 0 1 1 0 0 0 1 0\n",
      " 1 0 1 1 1 0 1 1 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 1 1 0 1 0 0 0 0 1 1 0 0 1 1\n",
      " 1 0 1 1 1 1 1 0 0 1 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 1 1 1 1 1 0 1 0 1 1 0 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 1 1 0 0 0 1 1\n",
      " 1 1 0 1 0 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0\n",
      " 0 1 0 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1\n",
      " 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 0 1 1 1 1 1 0 1 1\n",
      " 0 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1\n",
      " 1 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1 0 1 1 0 1 0 1 0 0\n",
      " 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 0 0 0 0 0 0 1]\n",
      "['malignant' 'benign']\n",
      "(569, 30)\n",
      "['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
      " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
      " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
      " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
      " 'smoothness error' 'compactness error' 'concavity error'\n",
      " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
      " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
      " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
      " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n",
      "1.0\n",
      "0.9574468085106383\n",
      "[ True  True  True  True  True  True  True  True  True  True False  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True False  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True False  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True False  True  True  True  True  True  True False\n",
      "  True  True False  True  True  True  True  True False  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True False  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True]\n",
      "0.9574468085106383\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9840425531914894"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ML can be used for diagnosis of disease as well\n",
    "\n",
    "from __future__ import print_function, division\n",
    "from future.utils import iteritems\n",
    "from builtins import range,input\n",
    "\n",
    "#install future pip install future\n",
    "\n",
    "#numpy incase we need it\n",
    "import numpy as np\n",
    "\n",
    "#import function that will get the data\n",
    "#yes, sklearn comes with built-in datasets\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "#load the data\n",
    "data = load_breast_cancer()\n",
    "\n",
    "print(type(data))\n",
    "\n",
    "#note : it is a Bunch object\n",
    "#this basically acts like a dictionary where you can treat the keys like attributes\n",
    "data.keys()\n",
    "print(data.keys())\n",
    "\n",
    "# 'data' (the attribute) means the input\n",
    "print(data.data)\n",
    "print(data.data.shape)\n",
    "\n",
    "#it has 569 samples, 30 features\n",
    "\n",
    "#'target' attributes\n",
    "print(data.target)\n",
    "#note how the targets are just 0s and 1s\n",
    "#normally, when you have k targets, they are labeled 0..K-1\n",
    "\n",
    "#their meaning is not lost\n",
    "print(data.target_names)\n",
    "\n",
    "#there are also 569 corresponding targets\n",
    "print(data.data.shape)\n",
    "\n",
    "#you can also determine the meaning of each feature\n",
    "print(data.feature_names)\n",
    "\n",
    "#normally we would put all of our imports at the top\n",
    "#but  this lets us tell a story\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "#split the data into train and test sets\n",
    "#this lets us simulate how our model will perform in future\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size = 0.33)\n",
    "\n",
    "#instantiate a classifier and train it\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "#evaluate the model's perfomance\n",
    "print(model.score(X_train, y_train))\n",
    "print(model.score(X_test, y_test))\n",
    "\n",
    "#how to make predictions\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "#what we get?\n",
    "predictions\n",
    "\n",
    "#manually check the accuracy of your predictions\n",
    "N=len(y_test)\n",
    "print(predictions==y_test)\n",
    "np.sum(predictions == y_test)/N \n",
    "print(np.sum(predictions == y_test)/N)#can also just call np.mean()\n",
    "\n",
    "# we can use deep learning to solve the same probkem!\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "#you will see why scaling is needed in a later course\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train2 = scaler.fit_transform(X_train)\n",
    "X_test2 = scaler.fit_transform(X_test)\n",
    "\n",
    "model = MLPClassifier(max_iter=500)\n",
    "#earlier we got a warning that the training hadn't converged, so let's make it train longer\n",
    "#Lesson to remember : Deep learning is not a \"plug and play\" type of algorithm\n",
    "model.fit(X_train2,y_train)\n",
    "\n",
    "#evaluate the model's perfomance\n",
    "model.score(X_train2,y_train)\n",
    "model.score(X_test2,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6242d42e-469f-4105-a3c3-fd6d95858655",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
